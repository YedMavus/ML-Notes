<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en-us lang=en-us><head><link href=https://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=generator content="Hugo 0.119.0"><meta name=viewport content="width=device-width,initial-scale=1"><title>Feature Extraction &#183; ML Notes</title><meta name=description content><link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/print.css media=print><link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/poole.css><link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/syntax.css><link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/hyde.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700"><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/favicon.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body class="theme-base-0d layout-reverse"><aside class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><a href=https://yedmavus.github.io/MLNotes/><h1>ML Notes</h1></a><p class=lead>Machine Learning Notes Based on Andrew Ng's ML lectures and NPTEL Lectures at IIT-Kgp | Course instructor Prof Ng and Prof Sudeshna Saha | Notes taken by Suvam Dey</p></div><nav><ul class=sidebar-nav><li><a href=https://yedmavus.github.io/MLNotes/>Home</a></li><li><a href=https://github.com/YedMavus/>Github</a></li><li><a href=https://www.linkedin.com/in/suvam-dey/>LinkedIn</a></li><li><a href=https://yedmavus.github.io/MLNotes/category/>PageHome</a></li></ul></nav><p>&copy; 2023. All rights reserved.</p></div></aside><main class="content container"><div class=post><h1>Feature Extraction</h1><time datetime=2021-08-24T00:00:00Z class=post-date>Tue, Aug 24, 2021</time><p>We find a projection matrix \( <strong>w</strong> \) such that \( \vec z = w^T \vec X \)</p><p>Also features have to have large variences</p><h2 id=principal-components>Principal Components</h2><p>Find w (eigenvecotrs) to get max varience, then lecond max , 3rd max etc till N dimensions are fulfilled</p><p><a href=https://drive.google.com/file/d/1Na9-bYu6uzGRZwI1KG-RX8C-f5JupFQT/view>More on PCA</a></p></div></main></body></html>