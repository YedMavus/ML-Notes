---
title: "Week 4 Lecture 1: Bayesian Learning; An Introduction"
date: 2021-08-25 00:00:00 +0000
katex: true
---

### Bayesian Probability 

Talks about probability interpretation based on partial beliefs.


### Bayesian Estimation

Calculates validity of a proposition: based on
- Prior Estimate of its prob
- New relevent evidence

## Baye's Theorem

\\( P(h|D) = \frac{P(D|h)P(h)}{P(D)} \\)

### How to apply this in ML?

MAP [ Maximum A Posteriori] Hypothesis

\\( h_MAP = argmax P(h|D) \\)
\\( h \epsilon H \\)

\\( = argmax(P(D|h)P(h)) \\)

#### Maximum Likely [ML] Hyp: In cases where all the hypothesis are equally probable.

\\( h_ML = argmax P(D|h) \\)
\\( h \epsilon H \\)


