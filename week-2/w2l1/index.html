<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en-us lang=en-us>
<head>
<link href=https://gmpg.org/xfn/11 rel=profile>
<meta charset=utf-8>
<meta name=generator content="Hugo 0.86.1">
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Week 2 Lecture 2: Linear Regression &#183; ML Notes</title>
<meta name=description content>
<link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/print.css media=print>
<link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/poole.css>
<link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/syntax.css>
<link type=text/css rel=stylesheet href=https://yedmavus.github.io/MLNotes/css/hyde.css>
<link rel=stylesheet href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">
<link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png>
<link rel="shortcut icon" href=/favicon.png>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
</head>
<body class="theme-base-0d layout-reverse">
<aside class=sidebar>
<div class="container sidebar-sticky">
<div class=sidebar-about>
<a href=https://yedmavus.github.io/MLNotes/><h1>ML Notes</h1></a>
<p class=lead>
Machine Learning Notes Based on Andrew Ng's ML lectures and NPTEL Lectures at IIT-Kgp | Course instructor Prof Ng and Prof Sudeshna Saha | Notes taken by Suvam Dey
</p>
</div>
<nav>
<ul class=sidebar-nav>
<li><a href=https://yedmavus.github.io/MLNotes/>Home</a> </li>
<li><a href=https://github.com/YedMavus/> Github </a></li><li><a href=https://www.linkedin.com/in/suvam-dey/> LinkedIn </a></li>
</ul>
</nav>
<p>&copy; 2021. All rights reserved. </p>
</div>
</aside>
<main class="content container">
<div class=post>
<h1>Week 2 Lecture 2: Linear Regression</h1>
<time datetime=2021-08-02T00:00:00Z class=post-date>Mon, Aug 2, 2021</time>
<p>\( \usepackage{graphicx} \)
\( \graphicspath{ {./images/} } \)</p>
<h1 id=week-2-lecture-2-linear-regression>Week 2 Lecture 2: Linear Regression</h1>
<h2 id=regression-in-x-and-y>Regression in X and Y</h2>
<h3 id=firstly-for-regression-y-is-continious>Firstly for <strong>regression</strong> Y is continious</h3>
<p>X \( \rightarrow \) Y</p>
<ul>
<li>Single Regression: X consists of only 1 feature
<ul>
<li>Find fucntion given arbitrary X, that can predict Y with minimum error</li>
<li>In <strong>Linear Regression</strong> this output Y function happens to be a line, trained based on an existing set of (X,Y)</li>
</ul>
</li>
<li>Multiple Regression: Multiple features in <strong>X</strong></li>
</ul>
<h2 id=linear-regression>Linear Regression</h2>
<h4 id=-y--beta-_0--beta-_-1-x->\( Y = \beta _0 + \beta _ 1 X \)</h4>
<p>Obviously, \( \beta _0 \) is the Y axis intercept, while \( \beta _ 1 \) is the population slope.</p>
</div>
</main>
</body>
</html>